{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39c44ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import glob\n",
    "import h5py\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openslide\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6558c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to raw TMA files.\n",
    "PATH_TO_RAW_DATA = \"/deep/group/aihc-bootcamp-fall2021/lymphoma/raw\"\n",
    "PATH_TO_IMAGES = os.path.join(PATH_TO_RAW_DATA, \"svs\")\n",
    "\n",
    "# Path to processed data (extracted TMA patches)\n",
    "PATH_TO_PROCESSED_DATA = \"/deep/group/aihc-bootcamp-fall2021/lymphoma/processed\"\n",
    "PATH_TO_TMA_PATCHES = os.path.join(PATH_TO_PROCESSED_DATA, \"tma_patches\")\n",
    "\n",
    "PATH_TO_TRAIN_DATA = os.path.join(PATH_TO_TMA_PATCHES, \"train.hdf5\")\n",
    "PATH_TO_VAL_DATA = os.path.join(PATH_TO_TMA_PATCHES, \"val.hdf5\")\n",
    "PATH_TO_TEST_DATA = os.path.join(PATH_TO_TMA_PATCHES, \"test.hdf5\")\n",
    "\n",
    "# Path to annotations and labels (diagnoses)\n",
    "PATH_TO_RAW_DATA = \"/deep/group/aihc-bootcamp-fall2021/lymphoma/raw\"\n",
    "PATH_TO_ANNOTATIONS_CSV = os.path.join(PATH_TO_RAW_DATA, \"cores\")\n",
    "PATH_TO_DIAGNOSES = os.path.join(PATH_TO_RAW_DATA, \"core_labels.csv\")\n",
    "\n",
    "CASE = \"CASE\"\n",
    "WHO_DIAGNOSIS = \"2017 WHO DIAGNOSIS\"\n",
    "CLPA_DIAGNOSIS = \"CLPA Diagnostic Bin\"\n",
    "LABEL = \"label\"\n",
    "TMA_ID = \"TMA ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8694e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of paths to TMA svs files and TMA annotations csv files.\n",
    "# We want the tma_slides_paths[i] to correspond to tma_annotations_paths[i] (hence, the calls to \"sort\").\n",
    "tma_slides_paths = sorted(glob.glob(PATH_TO_IMAGES + \"/*_TMA*.svs\"), key= lambda s : s.split(\"_\")[1])\n",
    "tma_annotations_paths = sorted(glob.glob(PATH_TO_ANNOTATIONS_CSV + \"/TMA*_annotations.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50de1503",
   "metadata": {},
   "outputs": [],
   "source": [
    "tma_names = [\"TMA1\", \"TMA2\", \"TMA3\", \"TMA4\", \"TMA5\", \"TMA6A\", \"TMA6B\", \"TMA8\"]\n",
    "tma_ids = [1, 2, 3, 4, 5, 6, 6, 8]\n",
    "tma_slides = [openslide.OpenSlide(tma_slide) for tma_slide in tma_slides_paths]\n",
    "tma_annotations = [pd.read_csv(filename) for filename in tma_annotations_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd21141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TMA ID</th>\n",
       "      <th>CASE</th>\n",
       "      <th>2017 WHO DIAGNOSIS</th>\n",
       "      <th>CLPA Diagnostic Bin</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>E0001 B</td>\n",
       "      <td>NOT ON TMA</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E0002 B</td>\n",
       "      <td>NON-DIAGNOSTIC</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>E0003 B</td>\n",
       "      <td>Classic Hodgkin Lymphoma</td>\n",
       "      <td>HL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>E0004 B</td>\n",
       "      <td>Follicular lymphoma, grade 1-2</td>\n",
       "      <td>FL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>E0005 B</td>\n",
       "      <td>Diffuse large B cell lymphoma, NOS</td>\n",
       "      <td>DLBCL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  TMA ID     CASE                  2017 WHO DIAGNOSIS  \\\n",
       "0           0       1  E0001 B                          NOT ON TMA   \n",
       "1           1       1  E0002 B                      NON-DIAGNOSTIC   \n",
       "2           2       1  E0003 B            Classic Hodgkin Lymphoma   \n",
       "3           3       1  E0004 B      Follicular lymphoma, grade 1-2   \n",
       "4           4       1  E0005 B  Diffuse large B cell lymphoma, NOS   \n",
       "\n",
       "  CLPA Diagnostic Bin  label  \n",
       "0            Excluded     -1  \n",
       "1            Excluded     -1  \n",
       "2                  HL      1  \n",
       "3                  FL      3  \n",
       "4               DLBCL      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tma_case_to_diagnosis = pd.read_csv(PATH_TO_DIAGNOSES, delimiter=',')\n",
    "tma_case_to_diagnosis[CLPA_DIAGNOSIS].value_counts()\n",
    "tma_case_to_diagnosis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22002716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Could not find diagnosis for: placenta\n",
      "Could not find diagnosis for: tonsil\n",
      "2\n",
      "Could not find diagnosis for: placenta\n",
      "Could not find diagnosis for: tonsil\n",
      "3\n",
      "Could not find diagnosis for: placenta\n",
      "Could not find diagnosis for: tonsil\n",
      "4\n",
      "Could not find diagnosis for: placenta\n",
      "Could not find diagnosis for: tonsil\n",
      "5\n",
      "Could not find diagnosis for: placenta\n",
      "Could not find diagnosis for: tonsil\n",
      "6\n",
      "Could not find diagnosis for: placenta\n",
      "Could not find diagnosis for: tonsil\n",
      "6\n",
      "Could not find diagnosis for: E0137\n",
      "Could not find diagnosis for: E0147\n",
      "Could not find diagnosis for: E0184\n",
      "Could not find diagnosis for: E0307\n",
      "Could not find diagnosis for: placenta\n",
      "Could not find diagnosis for: tonsil\n",
      "8\n",
      "Could not find diagnosis for: placenta\n",
      "Could not find diagnosis for: tonsil\n"
     ]
    }
   ],
   "source": [
    "# Builds a dataframe that maps each patient ID in the annotated TMAs to the corresponding diagnosis and label.\n",
    "def build_patient_to_label_df(tma_id, tma_annotations):\n",
    "    print(tma_id)\n",
    "    tma_patient_ids = sorted(list(set(tma_annotations[\"Name\"])))\n",
    "    tma_labels = pd.DataFrame()\n",
    "    missing_patient_ids = set([\"placenta\", \"tonsil\"])\n",
    "    clpa_diagnoses = []\n",
    "    labels = []\n",
    "    for patient_id in tma_patient_ids:\n",
    "        if patient_id in missing_patient_ids: # Do not consider placenta/tonsisl.\n",
    "            print(f\"Could not find diagnosis for: {patient_id}\")\n",
    "            diagnosis = \"Excluded\"\n",
    "            label = -1\n",
    "        else:\n",
    "            if not patient_id.rstrip()[-2].isspace() and patient_id.rstrip()[-1].isalpha():  # Add space between alphabet and number: \"E0456B\" -> \"E0456 B\"\n",
    "                patient_id = patient_id[:-1] + \" \" + patient_id[-1]\n",
    "            condition = (tma_case_to_diagnosis[CASE] == patient_id) & (tma_case_to_diagnosis[TMA_ID] == tma_id)\n",
    "            tma_case_to_diagnosis_row = tma_case_to_diagnosis[condition]\n",
    "            if len(tma_case_to_diagnosis_row[CLPA_DIAGNOSIS].values) == 0:\n",
    "                print(f\"Could not find diagnosis for: {patient_id}\")\n",
    "                diagnosis = \"Excluded\"\n",
    "                label = -1\n",
    "            else:\n",
    "                diagnosis = tma_case_to_diagnosis_row[CLPA_DIAGNOSIS].values[0]\n",
    "                label = tma_case_to_diagnosis_row[LABEL].values[0]\n",
    "        clpa_diagnoses.append(diagnosis)\n",
    "        labels.append(label)\n",
    "    tma_labels[\"patient_id\"] = tma_patient_ids\n",
    "    tma_labels[\"clpa_diagnosis\"] = clpa_diagnoses\n",
    "    tma_labels[\"label\"] = labels\n",
    "    return tma_labels\n",
    "\n",
    "tma_labels_df_list = [build_patient_to_label_df(tma_id, tma_annotation) for (tma_id, tma_annotation) \n",
    "                      in zip(tma_ids, tma_annotations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f4882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds a dictionary from each label to the list of patient ids with that label\n",
    "def build_label_to_patient_map(tma_labels_df):\n",
    "    label_to_patients = dict()\n",
    "    for label in range(0, 9):\n",
    "        patient_ids_with_label = list(tma_labels_df[tma_labels_df[LABEL] == label][\"patient_id\"].values)\n",
    "        label_to_patients[label] = patient_ids_with_label\n",
    "    return label_to_patients\n",
    "\n",
    "label_to_patients_list = [build_label_to_patient_map(tma_labels_df) for tma_labels_df in tma_labels_df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7136b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the data into a train:val:test ratio of 0.8 : 0.1 : 0.2\n",
    "# This method maintains this ratio for each diagnosis/label in the data. \n",
    "# For example, if we have 10 examples for label i: we randomly assign 8 to train, 1 to val, and 2 examples to test.\n",
    "def get_train_test_splits(label_to_patients, train_fraction=0.8, val_fraction=0.1):\n",
    "    train_patient_ids = []\n",
    "    val_patient_ids = []\n",
    "    test_patient_ids = []\n",
    "    \n",
    "    for label in label_to_patients:\n",
    "        patient_ids = label_to_patients[label]\n",
    "        if (len(patient_ids) <= 1): # Not enough patient IDs for this label to create a train/test split.\n",
    "            train_patient_ids.extend(patient_ids)\n",
    "        else:\n",
    "            # We make two calls to train_test_split to split the patients into train : val : test splits.\n",
    "            # 1) Call train_test_split to get train and test splits.\n",
    "            train_ids, test_ids = train_test_split(patient_ids, train_size=train_fraction)\n",
    "            if (len(train_ids) <= 1): # Not enough train patient IDs for this label to create a train/val split.\n",
    "                train_patient_ids.extend(train_ids)\n",
    "                test_patient_ids.extend(test_ids)\n",
    "            else:\n",
    "                # 2) Call train_test_split to split the train split into separate train and val splits.\n",
    "                train_ids, val_ids = train_test_split(train_ids, train_size=(1 - (val_fraction / train_fraction)))\n",
    "                train_patient_ids.extend(train_ids)\n",
    "                val_patient_ids.extend(val_ids)\n",
    "                test_patient_ids.extend(test_ids)\n",
    "    return (train_patient_ids, test_patient_ids, val_patient_ids)\n",
    "\n",
    "train_test_splits = [get_train_test_splits(label_to_patients) for label_to_patients in label_to_patients_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5404ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from DLBCL-Morph: extracting_roi_tma.ipynb.\n",
    "# Takes in a patch (PIL image) and returns whether or not the patch is sufficiently non-white.\n",
    "def is_patch_nonwhite_first(patch):\n",
    "    PERCENT_WHITE_PIXELS_THRESHOLD = 0.95\n",
    "    SAT_THRESHOLD = 0.05\n",
    "\n",
    "    hsv_patch = matplotlib.colors.rgb_to_hsv(patch)\n",
    "    saturation = hsv_patch[:,:,1]\n",
    "    percent = np.mean(saturation < SAT_THRESHOLD)\n",
    "    return percent <= PERCENT_WHITE_PIXELS_THRESHOLD\n",
    "\n",
    "# Taken from DLBCL-Morph: extracting_roi_tma.ipynb.\n",
    "# Takes in a patch (PIL image) and returns whether or not the patch is sufficiently non-white.\n",
    "def is_patch_nonwhite_second(patch):\n",
    "    GRAD_ZERO_THRESHOLD = 500\n",
    "    gray = cv.cvtColor(np.array(patch), cv.COLOR_RGB2GRAY)\n",
    "    sobelx = cv.Sobel(gray, cv.CV_64F, 1, 0, ksize=5)\n",
    "    sobely = cv.Sobel(gray, cv.CV_64F, 0, 1, ksize=5)\n",
    "    mag = np.abs(sobelx) + np.abs(sobely)\n",
    "    return np.sum(mag == 0) <= GRAD_ZERO_THRESHOLD\n",
    "\n",
    "# Extracts (default: 224 x 224) patches from a single core in the passed-in TMA.\n",
    "# The tissue core is defined by: top-left: (xs, ys), bottom-right: (xe, ye).\n",
    "# Only patches that are sufficiently non-white are returned.\n",
    "# Returns an np.array of dimension: n x 224 x 224 x 3 (where n = # of returned patches)\n",
    "def get_patches_from_core(tma, xs, ys, xe, ye, patch_size=224):\n",
    "    patches = []\n",
    "    for y in range(ys, ye, patch_size):\n",
    "        for x in range(xs, xe, patch_size):\n",
    "            patch = tma.read_region([x, y], 0, [patch_size, patch_size]).convert('RGB')\n",
    "            if is_patch_nonwhite_first(patch) and is_patch_nonwhite_second(patch):\n",
    "                patches.append(np.array(patch))\n",
    "    \n",
    "    if len(patches) == 0:\n",
    "        return np.array([])\n",
    "    return np.stack(patches)\n",
    "\n",
    "def get_field_by_patient_id(tma_id, patient_id, field):\n",
    "    missing_ids = set([\"placenta\", \"tonsil\"])\n",
    "    \n",
    "    if patient_id in missing_ids:\n",
    "        print(f\"Could not find {field} for: {patient_id}\")\n",
    "        return None\n",
    "    \n",
    "    elif not patient_id.rstrip()[-2].isspace() and patient_id.rstrip()[-1].isalpha():  # Add space between alphabet and number: \"E0456B\" -> \"E0456 B\"\n",
    "        patient_id = patient_id[:-1] + \" \" + patient_id[-1]\n",
    "    \n",
    "    condition = (tma_case_to_diagnosis[CASE] == patient_id) & (tma_case_to_diagnosis[\"TMA ID\"] == tma_id)\n",
    "    \n",
    "    if len(tma_case_to_diagnosis[condition][field].values) == 0:\n",
    "        print(f\"Could not find {field} for: {patient_id}\")\n",
    "        return None\n",
    "    \n",
    "    return tma_case_to_diagnosis[condition][field].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfcb79bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Train | Val | Test Splits for TMA: 1\n",
      "\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Building Train | Val | Test Splits for TMA: 2\n",
      "\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Building Train | Val | Test Splits for TMA: 3\n",
      "\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Building Train | Val | Test Splits for TMA: 4\n",
      "\n",
      "No patches found for TMA: 4, Patient: E0477B\n",
      "No patches found for TMA: 4, Patient: E0477B\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "No patches found for TMA: 4, Patient: E0456B\n",
      "No patches found for TMA: 4, Patient: E0477B\n",
      "No patches found for TMA: 4, Patient: E0404B\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "No patches found for TMA: 4, Patient: E0456B\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "No patches found for TMA: 4, Patient: E0477B\n",
      "No patches found for TMA: 4, Patient: E0456B\n",
      "No patches found for TMA: 4, Patient: E0390A\n",
      "Building Train | Val | Test Splits for TMA: 5\n",
      "\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "Building Train | Val | Test Splits for TMA: 6\n",
      "\n",
      "No patches found for TMA: 6, Patient: E0812B\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "No patches found for TMA: 6, Patient: E0715B\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "No patches found for TMA: 6, Patient: E0758B\n",
      "No patches found for TMA: 6, Patient: E0721B\n",
      "No patches found for TMA: 6, Patient: E0772B\n",
      "No patches found for TMA: 6, Patient: E0820B\n",
      "No patches found for TMA: 6, Patient: E0810B\n",
      "No patches found for TMA: 6, Patient: E0735B\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "No patches found for TMA: 6, Patient: E0758B\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "Building Train | Val | Test Splits for TMA: 6\n",
      "\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Could not find 2017 WHO DIAGNOSIS for: E0184\n",
      "Could not find CLPA Diagnostic Bin for: E0184\n",
      "Could not find label for: E0184\n",
      "No patches found for TMA: 6, Patient: E0919B\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "Could not find 2017 WHO DIAGNOSIS for: E0147\n",
      "Could not find CLPA Diagnostic Bin for: E0147\n",
      "Could not find label for: E0147\n",
      "Could not find 2017 WHO DIAGNOSIS for: E0137\n",
      "Could not find CLPA Diagnostic Bin for: E0137\n",
      "Could not find label for: E0137\n",
      "No patches found for TMA: 6, Patient: E0925B\n",
      "Could not find 2017 WHO DIAGNOSIS for: E0184\n",
      "Could not find CLPA Diagnostic Bin for: E0184\n",
      "Could not find label for: E0184\n",
      "Could not find 2017 WHO DIAGNOSIS for: E0137\n",
      "Could not find CLPA Diagnostic Bin for: E0137\n",
      "Could not find label for: E0137\n",
      "Could not find 2017 WHO DIAGNOSIS for: E0147\n",
      "Could not find CLPA Diagnostic Bin for: E0147\n",
      "Could not find label for: E0147\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "No patches found for TMA: 6, Patient: E0882B\n",
      "Could not find 2017 WHO DIAGNOSIS for: E0307\n",
      "Could not find CLPA Diagnostic Bin for: E0307\n",
      "Could not find label for: E0307\n",
      "Could not find 2017 WHO DIAGNOSIS for: E0307\n",
      "Could not find CLPA Diagnostic Bin for: E0307\n",
      "Could not find label for: E0307\n",
      "Building Train | Val | Test Splits for TMA: 8\n",
      "\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n",
      "Could not find 2017 WHO DIAGNOSIS for: placenta\n",
      "Could not find CLPA Diagnostic Bin for: placenta\n",
      "Could not find label for: placenta\n",
      "Could not find 2017 WHO DIAGNOSIS for: tonsil\n",
      "Could not find CLPA Diagnostic Bin for: tonsil\n",
      "Could not find label for: tonsil\n"
     ]
    }
   ],
   "source": [
    "def tma_to_data_splits(tma_id, tma_annotations, tma_slide,\n",
    "                       train_patient_ids, val_patient_ids, test_patient_ids,\n",
    "                       train_f, val_f, test_f):\n",
    "    patient_ids = set()\n",
    "    patient_id_repeats = {}\n",
    "    for index, row in tma_annotations.iterrows():\n",
    "        patient_id = row[\"Name\"]\n",
    "        name = f\"tma_{tma_id}_{patient_id}\"\n",
    "        \n",
    "        who_diagnosis = get_field_by_patient_id(tma_id, patient_id, WHO_DIAGNOSIS)\n",
    "        clpa_diagnosis = get_field_by_patient_id(tma_id, patient_id, CLPA_DIAGNOSIS)\n",
    "        label = get_field_by_patient_id(tma_id, patient_id, LABEL)\n",
    "        \n",
    "        # Don't include patient IDs whose labels we either don't know (None)\n",
    "        # or whose diagnosis is \"excluded\" (label = -1).\n",
    "        if label == None or label < 0:\n",
    "            continue\n",
    "        \n",
    "        if patient_id in train_patient_ids:\n",
    "            f = train_f\n",
    "        elif patient_id in val_patient_ids:\n",
    "            f = val_f\n",
    "        else:\n",
    "            assert(patient_id in test_patient_ids)\n",
    "            f = test_f\n",
    "        \n",
    "        # Deal with duplicate patients\n",
    "        if (patient_id not in patient_ids):\n",
    "            patient_id_repeats[patient_id] = 0\n",
    "        patient_id_repeats[patient_id] += 1\n",
    "        name += f\"_v{patient_id_repeats[patient_id]}\"\n",
    "        \n",
    "        xs, ys, width, height = int(row[\"X\"]), int(row[\"Y\"]), int(row[\"Width\"]), int(row[\"Height\"])\n",
    "        xe, ye = xs + width, ys + height\n",
    "        patches = get_patches_from_core(tma_slide, xs, ys, xe, ye)\n",
    "        \n",
    "        if patches.size == 0:\n",
    "            print(f\"No patches found for TMA: {tma_id}, Patient: {patient_id}\")\n",
    "            continue\n",
    "        \n",
    "        dset = f.create_dataset(name, data=patches, dtype='uint8')\n",
    "        dset.attrs['tma_id'] = tma_id\n",
    "        dset.attrs['patient_id'] = patient_id\n",
    "        dset.attrs['who_diagnosis'] = who_diagnosis\n",
    "        dset.attrs['clpa_diagnosis'] = clpa_diagnosis\n",
    "        dset.attrs['label'] = label\n",
    "        patient_ids.add(patient_id)\n",
    "    \n",
    "def build_train_test_splits(tma_ids, tma_slides, tma_annotations, train_test_splits):\n",
    "    assert(len(tma_slides) == len(tma_annotations))\n",
    "    train_f = h5py.File(PATH_TO_TRAIN_DATA, \"w\")\n",
    "    val_f = h5py.File(PATH_TO_VAL_DATA, \"w\")\n",
    "    test_f = h5py.File(PATH_TO_TEST_DATA, \"w\")\n",
    "    for i in range(len(tma_slides)):\n",
    "        tma_id = tma_ids[i]\n",
    "        print(f\"Building Train | Val | Test Splits for TMA: {tma_id}\\n\")\n",
    "        (train_patient_ids, val_patient_ids, test_patient_ids) = train_test_splits[i]\n",
    "        tma_to_data_splits(tma_id, tma_annotations[i], tma_slides[i],\n",
    "                           train_patient_ids, val_patient_ids, test_patient_ids,\n",
    "                           train_f, val_f, test_f)\n",
    "    train_f.close()\n",
    "    val_f.close()\n",
    "    test_f.close()\n",
    "\n",
    "build_train_test_splits(tma_ids, tma_slides, tma_annotations, train_test_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da523b1",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ad27af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_examples_in_data_split(path_to_data_split):\n",
    "    f = h5py.File(path_to_data_split, \"r\")\n",
    "    patient_ids = sorted(set([key for key in f.keys() if key.endswith(\"_v1\")]))\n",
    "    f.close()\n",
    "    return len(patient_ids)\n",
    "\n",
    "def get_patient_ids_by_tma_and_data_split(tma_id, path_to_data_split):\n",
    "    f = h5py.File(path_to_data_split, \"r\")\n",
    "    patient_ids = set([key.split(\"_\")[2] for key in f.keys() if key.startswith(f\"tma_{tma_id}\") and key.endswith(\"_v1\")])\n",
    "    f.close()\n",
    "    return patient_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc25f556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 386\n",
      "Number of validation examples: 138\n",
      "Number of testing examples: 78\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples:\", get_num_examples_in_data_split(PATH_TO_TRAIN_DATA))\n",
    "print(\"Number of validation examples:\", get_num_examples_in_data_split(PATH_TO_VAL_DATA))\n",
    "print(\"Number of testing examples:\", get_num_examples_in_data_split(PATH_TO_TEST_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ebbc800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training patient IDs from TMA 1: 43\n",
      "Expected Number of training patient IDs from TMA 1: 43\n"
     ]
    }
   ],
   "source": [
    "tma_id = 1\n",
    "tma_1_train_patient_ids = get_patient_ids_by_tma_and_data_split(tma_id, PATH_TO_TRAIN_DATA)\n",
    "print(f\"Number of training patient IDs from TMA {tma_id}:\", len(tma_1_train_patient_ids))\n",
    "\n",
    "expected_tma_1_train_patient_ids = train_test_splits[tma_id - 1][0]\n",
    "print(f\"Expected Number of training patient IDs from TMA {tma_id}:\", len(expected_tma_1_train_patient_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f29fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
