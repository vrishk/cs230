{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4bca7",
   "metadata": {},
   "source": [
    "## Inspect Available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a7fcb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: True \n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print('Using gpu: %s ' % use_gpu)\n",
    "\n",
    "def gpu(x,use_gpu=use_gpu):\n",
    "    if use_gpu:\n",
    "        return x.cuda()\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1949baa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available: True\n",
      "Cuda device count: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda is available:\", torch.cuda.is_available())\n",
    "print(\"Cuda device count:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f78075a",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e88bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TRAIN = \"/deep/group/aihc-bootcamp-fall2021/lymphoma/processed/data_splits/custom_splits/triplenet_features/triplenet_train_features.hdf5\"\n",
    "PATH_TO_VAL = \"/deep/group/aihc-bootcamp-fall2021/lymphoma/processed/data_splits/custom_splits/triplenet_features/triplenet_val_features.hdf5\"\n",
    "PATH_TO_TEST = \"/deep/group/aihc-bootcamp-fall2021/lymphoma/processed/data_splits/custom_splits/triplenet_features/triplenet_test_features.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305b847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, hdf5_path: str, transform=None):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.h5data = h5py.File(self.hdf5_path, \"r\")\n",
    "        self.cores = list(self.h5data.keys())\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cores)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.cores[idx]\n",
    "        patches = self.h5data[patient_id][()]\n",
    "        label = self.h5data[patient_id].attrs[\"y\"]\n",
    "        if self.transform:\n",
    "            patches = self.transform(patches)\n",
    "        return torch.tensor(patches), torch.tensor(int(label))\n",
    "\n",
    "class NaiveDataset(Dataset):\n",
    "    def __init__(self, hdf5_path: str, transform=None):\n",
    "\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.h5data = h5py.File(self.hdf5_path, \"r\")\n",
    "        self.cores = list(self.h5data.keys())\n",
    "        \n",
    "        self.lengths = [len(self.h5data[i]) for i in self.cores]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.lengths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        core_idx = 0\n",
    "        for l in self.lengths:\n",
    "            if idx - self.lengths[core_idx] < 0:\n",
    "                break\n",
    "            idx -= self.lengths[core_idx]\n",
    "            core_idx += 1\n",
    "        \n",
    "        \n",
    "        core_id = self.cores[core_idx]\n",
    "        patch: np.ndarray = self.h5data[core_id][()][idx]\n",
    "        label = self.h5data[core_id].attrs[\"y\"]\n",
    "        \n",
    "        if self.transform:\n",
    "            patch = self.transform(patch)\n",
    "\n",
    "        return patch, torch.tensor(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e4c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NaiveDataset(PATH_TO_TRAIN)\n",
    "val_dataset = NaiveDataset(PATH_TO_VAL)\n",
    "test_dataset = NaiveDataset(PATH_TO_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d0430e",
   "metadata": {},
   "source": [
    "## Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d0c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, num_workers=1, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, num_workers=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, num_workers=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0231c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3478011/2717790094.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlabel_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlabel_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# Output the label distribution in the train_dataloader\n",
    "label_counts = defaultdict(int)\n",
    "for (x,y) in train_dataloader:\n",
    "    label_counts[y.item()] += 1\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f7f41",
   "metadata": {},
   "source": [
    "## Create Linear Layer Above Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9bf1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(256*3, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LinearLayer(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291dc4af",
   "metadata": {},
   "source": [
    "## Define Optimizer and Loss Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35cea93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 1e-2\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "weights = [0.0058, 0.0156, 0.1861, 0.0357, 0.0291, 0.0994, 0.0341, 0.0542, 0.5400]\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(weights).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46361a04",
   "metadata": {},
   "source": [
    "## Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47cc2091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, epochs=1):\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    val_loss_history = []\n",
    "    val_accuracy_history = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        model.train()\n",
    "        batches = train_dataloader\n",
    "        num_correct, num_samples, total_loss = 0, 0, 0\n",
    "        i = 0\n",
    "        for x, y in tqdm(batches):\n",
    "            optimizer.zero_grad()\n",
    "            # x, y = gpu(x.squeeze(dim=0)), gpu(y)\n",
    "            x, y = gpu(x), gpu(y)\n",
    "            scores = model(x)\n",
    "            # aggregated_scores = torch.max(scores, 0, keepdim=True)[0]\n",
    "            # loss = criterion(aggregated_scores, y)\n",
    "            loss = criterion(scores, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # _,preds = torch.max(aggregated_scores, 1)\n",
    "            _,preds = torch.max(scores, 1)\n",
    "            total_loss += loss.data.item()\n",
    "            num_correct += torch.sum(preds == y.data)\n",
    "            num_samples += preds.size(0)\n",
    "            i += 1\n",
    "        print(f\"Completed {i} iterations in epoch\")\n",
    "        average_loss = total_loss / num_samples\n",
    "        acc = num_correct / num_samples\n",
    "        train_loss_history.append(average_loss)\n",
    "        train_accuracy_history.append(acc)\n",
    "        print('Epoch: {} Training Loss: {:.4f} Got {} / {} correct. Acc: {:.2f}%'.format(\n",
    "                     epoch + 1, average_loss, num_correct, num_samples, 100 * acc))\n",
    "        \n",
    "        check_accuracy(model, val_loss_history, val_accuracy_history, epoch)\n",
    "    return train_loss_history, train_accuracy_history, val_loss_history, val_accuracy_history\n",
    "\n",
    "def check_accuracy(model, val_loss_history, val_accuracy_history, epoch):\n",
    "    num_correct, num_samples, total_loss = 0, 0, 0\n",
    "    model.eval()\n",
    "    batches = val_dataloader\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(batches):\n",
    "            # x, y = gpu(x.squeeze(dim=0)), gpu(y)\n",
    "            x, y = gpu(x), gpu(y)\n",
    "            scores = model(x)\n",
    "            # aggregated_scores = torch.max(scores, 0, keepdim=True)[0]\n",
    "            # loss = criterion(aggregated_scores, y)\n",
    "            loss = criterion(scores, y)\n",
    "            # _, preds = torch.max(aggregated_scores, 1)\n",
    "            _, preds = torch.max(scores, 1)\n",
    "            total_loss += loss.data.item()\n",
    "            num_correct += torch.sum(preds == y.data)\n",
    "            num_samples += preds.size(0)\n",
    "        average_loss = total_loss / num_samples\n",
    "        acc = num_correct / num_samples\n",
    "    val_loss_history.append(average_loss)\n",
    "    val_accuracy_history.append(acc)\n",
    "    print('Epoch: {} Validation Loss: {:.4f} Got {} / {} correct {:.2f}%'.format(\n",
    "        epoch + 1, average_loss, num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be510e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d23730ecc664db7aa0c6e0667069766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "LOSS, ACC, LOSS_V, ACC_V = train_model(gpu(model), optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62edf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"triplenet_model.dat\"\n",
    "torch.save(model, PATH)\n",
    "print(\"Successfully saved model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6438ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the model parameters after training.\n",
    "for name, param in model.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c672998",
   "metadata": {},
   "source": [
    "## Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"triplenet_model.dat\"\n",
    "loaded_model = torch.load(PATH)\n",
    "loaded_model = gpu(loaded_model)\n",
    "model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38950679",
   "metadata": {},
   "source": [
    "## Resume Training with Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50494584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%%time\n",
    "num_epochs = 20\n",
    "LOSS, ACC, LOSS_V, ACC_V = train_model(gpu(model), optimizer, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "173e6da4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "PATH = f\"./model_ckpts/triplenet_finetune_epochs_{num_epochs}.dat\"\n",
    "torch.save(model, PATH)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eaa941",
   "metadata": {},
   "source": [
    "## Evaluate Top-1, Top-3 Accuracy on Test Set + Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e629a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f\"./model_ckpts/triplenet_finetune_epochs_{num_epochs}.dat\")\n",
    "model = gpu(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60347b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67e1a8b41ee4d338de6cf2e4ff7cd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 Accuracy of the network on the all test images: 38.01 %\n"
     ]
    }
   ],
   "source": [
    "def compute_top_1_accuracy(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batches = test_dataloader\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(batches):\n",
    "            x, y = gpu(x.squeeze(dim=0)), gpu(y)\n",
    "            scores = model(x)\n",
    "            # aggregated_scores = torch.max(scores, 0, keepdim=True)[0]\n",
    "            # _, preds = torch.max(aggregated_scores, 1)\n",
    "            _, preds = torch.max(scores, 1)\n",
    "            total += preds.size(0)\n",
    "            correct += (preds == y).sum().item()\n",
    "\n",
    "    print('Top 1 Accuracy of the network on the all test images: %.2f %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "compute_top_1_accuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1ad1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add17dcb8125415bb9baf32685ad42a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_top_3_accuracy(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for x, y in tqdm(test_dataloader):\n",
    "            x, y = gpu(x.squeeze(dim=0)), gpu(y)\n",
    "            scores = model(x)\n",
    "            # aggregated_scores = torch.max(scores, 0, keepdim=True)[0]\n",
    "            # _, preds = torch.topk(aggregated_scores, 3, dim=1)\n",
    "            _, preds = torch.topk(scores, 3, dim=1)\n",
    "            total += y.size(0)\n",
    "            for i in range(preds.shape[0]):\n",
    "                top_5_predictions = preds[i]\n",
    "                label = y[i]\n",
    "                if label in top_5_predictions:\n",
    "                    correct += 1\n",
    "    print('Top 3 Accuracy of the network on the all test images: %.2f %%' % (\n",
    "        100 * correct / total))\n",
    "    \n",
    "compute_top_3_accuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c745f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store y_pred and y_test on the test set for evaluation.\n",
    "\n",
    "y_pred = []\n",
    "y_test = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x, y in test_dataloader:\n",
    "        x, y = gpu(x.squeeze(dim=0)), gpu(y)\n",
    "        scores = model(x)\n",
    "        # aggregated_scores = torch.max(scores, 0, keepdim=True)[0]\n",
    "        # _, predicted = torch.max(aggregated_scores, 1)\n",
    "        _, predicted = torch.max(scores, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy().tolist())\n",
    "        y_test.extend(y.cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c51b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix\\n')\n",
    "print(cnf_matrix)\n",
    "print(cnf_matrix[0][0], sum(cnf_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9485d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8\n",
    "array = cnf_matrix.tolist()\n",
    "df_cm = pd.DataFrame(array, index = [i for i in range(8)],\n",
    "                  columns = [i for i in range(8)])\n",
    "plt.figure(figsize = (8,8))\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e318d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
